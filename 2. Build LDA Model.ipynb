{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Build Model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2feTQM2mS933"
      },
      "source": [
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "from gensim.parsing.preprocessing import preprocess_string, strip_punctuation, strip_numeric\n",
        "from gensim import corpora\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "from gensim.models import LdaModel\n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VqJ7zbFR-1y"
      },
      "source": [
        "def prepare_corpus(dataset):\n",
        "\n",
        "  # Remove common words\n",
        "  data = []\n",
        "  for d in dataset:\n",
        "    words = []\n",
        "    for word in d.split():\n",
        "      if word not in ['covid', 'corona', 'pandemi'] and len(word) > 3:\n",
        "        words.append(word)\n",
        "    data.append(words)\n",
        "    \n",
        "  # Creating the term dictionary of our courpus, where every unique term is assigned an index. dictionary = corpora.Dictionary(doc_clean)\n",
        "  dictionary = corpora.Dictionary(data)\n",
        "  # Converting list of documents (corpus) into Document Term Matrix using dictionary prepared above.\n",
        "  doc_term_matrix = [dictionary.doc2bow(doc) for doc in data]\n",
        "  # generate LDA model\n",
        "  return data, dictionary, doc_term_matrix\n",
        "\n",
        "def compute_coherence_values(dictionary, doc_term_matrix, doc_clean, stop, start=2, step=3):\n",
        "  # Compute coherence values to determine number of topics\n",
        "  coherence_values = []\n",
        "  model_list = []\n",
        "  for num_topics in range(start, stop, step):\n",
        "    # generate LSA model\n",
        "    model = LdaModel(doc_term_matrix, num_topics=num_topics, id2word=dictionary)\n",
        "    model_list.append(model)\n",
        "    coherencemodel = CoherenceModel(model=model, texts=doc_clean, dictionary=dictionary, coherence='c_v')\n",
        "    coherence_values.append(coherencemodel.get_coherence())\n",
        "  return coherence_values\n",
        "\n",
        "def best_topic(dataset,start, stop, step):\n",
        "  # Prepare corpus\n",
        "  data,dictionary,doc_term_matrix=prepare_corpus(dataset)\n",
        "  \n",
        "  # Compute coherence values\n",
        "  coherence_values = compute_coherence_values(dictionary, doc_term_matrix, data, stop, start, step)\n",
        "  \n",
        "  max_value = max(coherence_values)\n",
        "  number_of_topics = coherence_values.index(max_value) + 2\n",
        "  \n",
        "  return dictionary, doc_term_matrix, number_of_topics\n",
        "\n",
        "def create_gensim_lda_model(dataset):\n",
        "  start,stop,step=2,12,1\n",
        "  dictionary, doc_term_matrix, number_of_topics = best_topic(dataset,start,stop,step)\n",
        "\n",
        "  # Generate LSA model\n",
        "  model = LdaModel(doc_term_matrix, num_topics = number_of_topics, id2word=dictionary, update_every=1, chunksize=100, random_state=42, passes=10, alpha='auto' )\n",
        "\n",
        "  topics = []\n",
        "  filters = [lambda x: x.lower(), strip_punctuation, strip_numeric]\n",
        "\n",
        "  lda_topics = model.show_topics(num_words=5)\n",
        "\n",
        "  for topic in lda_topics:\n",
        "    topics.append(preprocess_string(topic[1], filters))\n",
        "\n",
        "  return dictionary, doc_term_matrix, model, topics, number_of_topics"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "4TSAPxEWSgea",
        "outputId": "d69bdc36-be5f-4576-8f42-a88ac3630a37"
      },
      "source": [
        "# Import data\n",
        "dataset = pd.read_csv('https://raw.githubusercontent.com/ahmaulana/topic-modelling/main/dataset.csv', index_col=0)\n",
        "def remove_punct(text):\n",
        "    text = re.sub(r'[^a-zA-Z_]', ' ', str(text))\n",
        "    return text\n",
        "\n",
        "dataset.prepro = dataset.prepro.apply(remove_punct)\n",
        "\n",
        "# Build LDA Model\n",
        "dictionary, corpus, model, topics, number_of_topics = create_gensim_lda_model(dataset.prepro)\n",
        "\n",
        "# Topic Lists\n",
        "topic_lists = pd.DataFrame(list(zip([*range(0, number_of_topics, 1)], topics)), columns=['Topic', 'Words'])\n",
        "topic_lists"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topic</th>\n",
              "      <th>Words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>[cegah, prokes, disiplin, tular, vaksinasi]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>[nyata, metode, swab, protes, kontribusi]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>[indonesia, pulih, perintah, masyarakat, ppkm]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>[stop, hoaks, tingkat, susu, turun]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>[optimis, vaksinasi, aman, halal, tekan]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>[sigit, listyo, prabowo, jenderal, vaksinasi]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>[jaga, anak, hindar, muka, tatap]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>[vaksin, ajar, lawan, hati, tindak]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>[masker, dampak, salur, giat, tangan]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Topic                                           Words\n",
              "0      0     [cegah, prokes, disiplin, tular, vaksinasi]\n",
              "1      1       [nyata, metode, swab, protes, kontribusi]\n",
              "2      2  [indonesia, pulih, perintah, masyarakat, ppkm]\n",
              "3      3             [stop, hoaks, tingkat, susu, turun]\n",
              "4      4        [optimis, vaksinasi, aman, halal, tekan]\n",
              "5      5   [sigit, listyo, prabowo, jenderal, vaksinasi]\n",
              "6      6               [jaga, anak, hindar, muka, tatap]\n",
              "7      7             [vaksin, ajar, lawan, hati, tindak]\n",
              "8      8           [masker, dampak, salur, giat, tangan]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3Z24CrEVquV"
      },
      "source": [
        "# Save Model\n",
        "path = 'model'\n",
        "os.mkdir(path)\n",
        "model.save(path + '/topic.model')"
      ],
      "execution_count": 4,
      "outputs": []
    }
  ]
}